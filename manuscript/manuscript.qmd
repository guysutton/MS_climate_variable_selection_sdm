---
title: Climate predictor selection and variable reduction methods influence MaxEnt model performance and predictions of climatic suitability 
author:
  - name: Clarke van Steenderen
    email: vsteenderen@gmail.com
    affiliations: 
        - id: some-tech
          name: Center for Biological Control, Department of Zoology and Entomology
          department: Rhodes University
          address: 
          city: Makhanda
          state: South Africa
          postal-code: 6140
    attributes:
        corresponding: false
  - name: Guy F. Sutton
    email: g.sutton@ru.ac.za
    affiliations:
        - id: another-u
          name: Center for Biological Control, Department of Zoology and Entomology
          department: Rhodes University
          address: 
          city: Makhanda
          state: South Africa
          postal-code: 6140
    attributes:
        corresponding: true
abstract: |
  This is the abstract. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum augue turpis, dictum non malesuada a, volutpat eget velit. Nam placerat turpis purus, eu tristique ex tincidunt et. Mauris sed augue eget turpis ultrices tincidunt. Sed et mi in leo porta egestas. Aliquam non laoreet velit. Nunc quis ex vitae eros aliquet auctor nec ac libero. Duis laoreet sapien eu mi luctus, in bibendum leo molestie. Sed hendrerit diam diam, ac dapibus nisl volutpat vitae. Aliquam bibendum varius libero, eu efficitur justo rutrum at. Sed at tempus elit.
keywords: 
  - Species distribution model
  - Variable selection
  - Ecological model
  - WORLDCLIM
date: last-modified
bibliography: bibliography.bib
format:
  elsevier-pdf:
    keep-tex: true
    journal:
      name: Ecological Modelling
      formatting: preprint
      model: 3p
      layout: twocolumn
      cite-style: authoryear
      highlights:
        - Highlight 1
        - Highlight 2 
        - Highlight 3
---

# 1. Introduction 

Ecological models are important tools to aid the development and implementation of environmental policies and management programmes [@Addison2013; @Schuwirth2019; @Sutton2022]. These models are used for conservation planning [@Guisan2013], predicting the establishment and spread of invasive species [@Martin2020], implementing biological control programmes [@Sutton2019b; @Mukherjee2021], and forecasting species responses to environmental change [@Bocedi2014], amongst other applications. Species distribution models (SDM’s) are an example of ecological models that have become increasingly popular in recent years [@Elith2009]. SDM’s typically take the form of correlative or mechanistic models that correlate species presence/absences (or pseudo-absences) to environmental covariates to identify suitable climatic conditions for the study taxon [@Elith2011]. The Maximum Entropy species distribution model (hereafter ‘MaxEnt’) is amongst the most popular methods for climate modelling studies and has been shown to perform well compared to alternative modelling algorithms [@Wisz2008; @Phillips2017]. It uses maximum entropy to distinguish between environmental conditions where the focal taxon is present from environmental conditions at sites without confirmed presence records for the taxon [@Elith2011].

In recent years, a number of studies have investigated and demonstrated that computational choices made during the model building process can have a significant influence on resulting model outputs and inferences drawn [@Warren2011; @Webber2011; @Shcheglovitova2013; @Boria2017; @Sutton2022]. Despite its importance in the model building process, covariate selection methods have received considerably little attention to date [but see @Austin2011; @Fourcade2018; @Adde2023], whereby covariate selection refers to "identify[ing] the best subset of covariates out of a panel of many candidates, both from an ecological and statistical perspective [see @Adde2023 and references therein]. 

**Next paragraphs** 

- Review current methods used to select variables, e.g. R2, VIF, PCA, expert opinion, and most recently, automated selection / model-based selection. 

- Aims of this paper are to show how variable selection can influence model outputs and inferences. 

# 2. Methods and materials 

### 2.1. Species occurrence records

- Clarke to add information on where we sourced GPS records - link to key papers, maybe a supplementary table (if required).
- How many records do we have? 

Spatial autocorrelation is an important factor that may affect model outputs. Filtering of species occurrence data may limit the inherent biases in the data and improve model quality (Veloz, 2009). To avoid pseudo-replication, only one occurrencenrecord per 2.5 min grid cell was used for model calibration. Species occurrence datasets were thinned using the ‘*spThin*’ package [@Aiello-Lammens2015], and spatial autocorrelation analyses were performed using the ‘*ecospat*’ package [@DiCola2017]. Eighty-eight occurrence records were retained to calibrate native-range models. Spatial thinning was also performed for the invaded range occurrences, however, there was no evidence for spatial autocorrelation. As such, no occurrence records were thinned for the invaded-range dataset.

### 2.2. Environmental predictors

Climate data were obtained by downloading the standard set of 19 bioclimatic variables from the WorldClim ver. 2.1 database [@Fick2017] (data available at: www.worldclim.org/download.html). This dataset is representative of annual and seasonal means and variation of temperature and precipitation metrics averaged over the 1950–2000 time period (current climate) at a 2.5 minute resolution. These variables have been shown to effectively model the climatic suitability for non-native insects (e.g., @Sutton2022). 

### 2.3. Model calibration 

MaxEnt (ver. 3.4.3) was implemented in the ‘*dismo*’ R package (@Hijmans2017).

Given that MaxEnt is a presence/pseudo-absence modelling algorithm, model calibration requires a user-defined geographic background to sample the climate of representative grid cells where the focal species is assumed to be absent (i.e., background points or pseudo-absences). Background definition can have a significant effect on model output (VanDerWal et al., 2009). The background should ideally represent the geographic areas available to the focal species, omitting areas where species absence is due to historical factors, dispersal constraints and/or biotic interactions (Sanin and Anderson, 2018). Following Webber et al. (2011), we defined the model background using the Koppen-Geiger climate classification system (available at: http://koeppen-geiger.vu-w ien.ac.at). Only Koppen-Geiger climate zones that contained at least one native-range occurrence record for D. rubiformis in Australia were used as the background area from which background points were drawn for model calibration (Fig. 1a). The Koppen-Geiger climate zones were intersected with the occurrence records using the ‘ raster’ R package (Hijmans, 2022). We randomly sampled 10 000 points (the default number used for Maxent; Merow et al. (2013) ) from within this background definition using the ‘dismo’ R package (Hijmans et al., 2021).

MaxEnt models were parameterised with default settings for multiple parameters, including: convergence = 105, maximum number of iterations = 500 and prevalence = 0.5. The ‘fade by clamping’ option was selected to prevent extrapolation well outside the range of climatic values in the model training area (Philips et al., 2017 ). Model predictions were obtained using the ‘logistic output’ to create continuous climatic suitability raster layers scaled between 0 (climatically unsuitable) and 1 (climatically suitable).

### 2.4. Model evaluation 

Model tuning experiments were applied to the native-range MaxEnt models to derive within-sample evaluation metrics to guide the selection of optimal MaxEnt parameter configurations (feature classes and regularisation multipliers). Optimised parameter configurations would then be used to refit the MaxEnt models before being projected into a novel geographic region and making projections of climatic suitability for D. rubiformis . Model tuning was performed by building MaxEnt models with varying (1) feature class combinations (H = Hinge only, L = Linear only, LQ = Linear and Quadratic and LQH = Linear, Quadratic and Hinge features) and (2) regularisation multipliers (1:8). In total, 32 MaxEnt models were specified. Native-range model performance and optimal parameter configurations were assessed using 4-fold spatial block cross validation using ‘ENMeval’ (Kass et al., 2021). 

Optimal parameter configurations were assessed using multiple metrics that reflect different aspects of model performance. Four metrics were calculated, including: (1) discriminatory ability (AUCtest), (2) overfitting (AUCdiff), (3) omission rates (OR10), and (4) overall parsimony (AICc). The use of AUC analyses for assessing the fit of MaxEnt models has been criticised for a variety of reasons (see Lobo et al., 2008; Peterson et al., 2008 ). However, AUC metrics are arguably the most widely used metrics to evaluate MaxEnt model performance, and as such, we believe it is important to include them in our evaluation, and contrast the results obtained using AUC versus other metrics.

We specified five final MaxEnt models, four models calibrated with FC and RM values that optimised model performance based on the metricsdiscussed below, and a MaxEnt model calibrated with default FC and RM values. Our intention was to compare MaxEnt model predictions and perfor mance depending on which metric was used to select optimal parameter configurations relative to the default MaxEnt settings. 

(1) AUC test assesses the model ’s ability to discriminate between predicted presence at withheld portions of the data used to test the model versus pseudo-absence points. An AUC of less than 0.8 is considered a poor model, between 0.8 and 0.9 is a fair model, between 0.9 and 0.995 a good model, and > 0.995 an excellent model (Fielding and Bell, 1997). Thus, higher AUCtest values indicate increased ability to discriminate between testing and background points.

(2) AUC diff is the difference between AUC values calculated on training points only (AUCtrain) and AUCtest [see (1) AUCtest above for details] (Warren and Seifert, 2011). Thus, higher AUCdiff values indicate whether the MaxEnt model is overfit on the training data, and thus, may perform poorly when evaluated against testing points. 

(3) OR 10 is the 10% training omission rate (Boria et al., 2014 ). Overfit models have omission rates higher than the theoretical expectation for the threshold applied (Shcheglovitova and Anderson, 2013). As such, the OR 10 criterion selected models calibrated with MaxEnt settings which best approximated the expected 0.10 omission rate. Models with omission rates increasingly higher than the expected value were considered to have a higher degree of overfit (Boria et al., 2017). 

(4) The Akaike Information Criterion corrected for small sample sizes (AICc) criterion simultaneously scores models according to their complexity and goodness-of-fit. AICc was used as the primary evaluation metric as it is calculated using MaxEnt models built using the entire species occurrence dataset (i.e. all the occurrence points in the native-range), unlike AUC and OR10 (and numerous other metrics frequently used for model evaluation) which may be spatially biased due to the partitioning of the species occurrence dataset into training and evaluation sets (Sanin and Anderson, 2018). Optimal parameter configurations were determined by selecting model configurations which produced the lowest value for AICc (i.e., AICc=0; following Kass et al. (2021)).

### 2.5. Model visualisation 

- Need to discuss how we map the different rasters, and maybe how we quantified the difference in suitability projections between climate layers? 




All modelling and statistical analyses were conducted in R ver. 4.0.3 (R Core Team, 2020). All values presented in text are presentedas mean ± standard error, unless otherwise stated. A standardised ODMAP methods protocol (Overview, Data, Model, Assessment, and Prediction) has been completed for this study and can be found in Supplementary File S1. ODMAP standardises the reporting of SDM modelling studies to improve transparency and reproducibility (Zurell et al., 2020).


# 3. Results


# 4. Discussion 






# Declaration of Competing Interest 

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Data availability 

All data and code required to reproduce the analyses are available in a public GitHub repository: https://github.com/guysutton/MS_climate_variable_selection_sdm

# Acknlowedgements 

CVS and GFS acknowledge funding from the South African Working for Water (WfW) programme of the Department of Forestry, Fisheries and the Environment: Natural Resource Management Programmes (DFFE: NRMP). Funding was also provided by the South African Research Chairs Initiative of the Department of Science and Technology and the National Research Foundation (NRF) of South Africa. Any opinions, finding, conclusions or recommendations expressed in this material are those of the authors and the NRF does not accept any liability in this regard.

# Supplementary materials 


# References 






















